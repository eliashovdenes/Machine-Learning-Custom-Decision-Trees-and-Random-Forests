{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 â€“ Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Reload all modules without having to restart the kernel\n",
    "# Useful for development if you have edited any of the external code files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# My implementations\n",
    "from decision_tree import DecisionTree\n",
    "from random_forest import RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Do data loading, exploration and preprocessing as you see fit.\n",
    "\n",
    "Here is some code to load the dataset to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns names: ['citric_acid', 'residual_sugar', 'pH', 'sulphates', 'alcohol']\n",
      "Target column name: type\n",
      "X shape: (500, 5)\n",
      "y shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"wine_dataset_small.csv\", delimiter=\",\", dtype=float, names=True)\n",
    "\n",
    "feature_names = list(data.dtype.names[:-1])\n",
    "target_name = data.dtype.names[-1]\n",
    "\n",
    "X = np.array([data[feature] for feature in feature_names]).T\n",
    "y = data[target_name].astype(int)\n",
    "\n",
    "print(f\"Feature columns names: {feature_names}\")\n",
    "print(f\"Target column name: {target_name}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Set Random Seeds. Create a requirements.txt. Document Hyperparameters. Use Version Control. '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which hyperparameters should you tune?\n",
    "\n",
    "\"\"\" I think the max_depth, n_estimators(how many trees), criterion, max_features \"\"\"\n",
    "\n",
    "# Which values should you test for each hyperparameter?\n",
    "\n",
    "\"\"\"max_depth: 1 to 15?,    n_estimators: 1 to 200,   criterion: entropy or gini,  max_features: sqrt or log2 or None\"\"\"\n",
    "\n",
    "# Which model selection method should you use (e.g., hold-out validation, k-fold cross-validation)?\n",
    "\n",
    "\"\"\"k-fold cross-validation: This is ideal because it splits the dataset into k subsets (e.g., k=5), trains the model on k-1 folds, and tests on the remaining fold. The process is repeated k times with different folds. This helps to reduce the risk of overfitting to a particular subset of data.\n",
    "\n",
    "Why: It ensures that your model isn't overly tuned to any specific training or testing split and provides a more generalized measure of performance.\"\"\"\n",
    "\n",
    "# Which performance measure should you use for model selection (e.g., accuracy, F1-score)?\n",
    "\n",
    "\"\"\"Accuracy is fine becuase i think that there wont be class imbalance in the classes, if it were we should use F1-score. Try both\"\"\"\n",
    "\n",
    "# How do you ensure that your model selection process is fair and unbiased?\n",
    "\n",
    "\"\"\"follow best practices in data splitting, hyperparameter tuning, and evaluation. Avoid Data Leakage. Avoid Overfitting. Ensure Class Balance \"\"\"\n",
    "\n",
    "# How can you ensure reproducibility of your results?\n",
    "\n",
    "\"\"\"Set Random Seeds. Create a requirements.txt. Document Hyperparameters. Use Version Control. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed \n",
    "seed = 0\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "#Split the data into test and (training and validation)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X,y, test_size=0.3, random_state=seed, shuffle=True)\n",
    "\n",
    "# Use k fold cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of hyperparameters that i want to tune\n",
    "\n",
    "# Decision tree:\n",
    "decision_tree_max_depth_params = [3,5,8,10,12,15,17,20,None]\n",
    "\n",
    "# Random forest:\n",
    "max_depth_params = [3,10,15,20,None]\n",
    "\n",
    "n_estimators = [2,10,15,20]\n",
    "\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "\n",
    "max_features = [\"sqrt\", \"log2\", None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for tuning random forest using k-fold cross validation\n",
    "\n",
    "def tune_random_forest(model_type, X_train_val, y_train_val, n_estimators, max_depth_params, criterion, max_features, kf):\n",
    "    best_accuracy = [0]  # To store the best average accuracy and the corresponding hyperparameters\n",
    "    \n",
    "    # Iterate through all combinations of hyperparameters\n",
    "    for maxdp in max_depth_params:\n",
    "        for n_est in n_estimators:\n",
    "            for crit in criterion:\n",
    "                for mf in max_features:\n",
    "                    \n",
    "                    # Instantiate the model based on the input string\n",
    "                    if model_type == \"RandomForest\":\n",
    "                        rf = RandomForest(n_estimators=n_est, max_depth=maxdp, criterion=crit, max_features=mf, seed=seed)\n",
    "                    elif model_type == \"SklearnRandomForest\":\n",
    "                        rf = RandomForestClassifier(n_estimators=n_est, max_depth=maxdp, criterion=crit, max_features=mf , random_state=seed)\n",
    "                    else:\n",
    "                        raise ValueError(\"Invalid model_type. Choose either 'RandomForest' or 'SklearnRandomForest'.\")\n",
    "                    \n",
    "                    # List to store accuracies for each fold\n",
    "                    fold_accuracies = []\n",
    "                    \n",
    "                    # Perform k-fold cross-validation\n",
    "                    for train_index, val_index in kf.split(X_train_val):\n",
    "                        # Split the data into training and validation sets for each fold\n",
    "                        X_training, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "                        y_training, y_val = y_train_val[train_index], y_train_val[val_index]\n",
    "                        \n",
    "                        # Train the model on the training set\n",
    "                        rf.fit(X_training, y_training)\n",
    "                        \n",
    "                        # Predict on the validation set\n",
    "                        y_pred = rf.predict(X_val)\n",
    "                        \n",
    "                        # Calculate accuracy for the current fold\n",
    "                        accuracy = accuracy_score(y_val, y_pred)\n",
    "                        fold_accuracies.append(accuracy)\n",
    "                    \n",
    "                    # Calculate average accuracy across all folds\n",
    "                    average_accuracy = np.mean(fold_accuracies)\n",
    "                    \n",
    "                    # Update best accuracy and hyperparameters if current average is better\n",
    "                    if average_accuracy > best_accuracy[0]:\n",
    "                        best_accuracy = [average_accuracy, n_est, maxdp, crit, mf]\n",
    "    \n",
    "    # Return the best hyperparameters and accuracy\n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for tuning decision tree using k-fold cross validation\n",
    "\n",
    "def tune_decision_tree(model_type, X_train_val, y_train_val, max_depth_params, criterion, max_features, kf):\n",
    "    best_accuracy = [0]  # To store the best average accuracy and the corresponding hyperparameters\n",
    "    \n",
    "    # Iterate through all combinations of hyperparameters\n",
    "    for maxdp in max_depth_params:\n",
    "            for crit in criterion:\n",
    "                for mf in max_features:\n",
    "                    \n",
    "                    # Instantiate the model based on the input string\n",
    "                    if model_type == \"DecisionTree\":\n",
    "                        rf = DecisionTree(max_depth=maxdp, criterion=crit, max_features=mf, seed=33)\n",
    "                    elif model_type == \"SklearnDecisionTree\":\n",
    "                        rf = DecisionTreeClassifier(max_depth=maxdp, criterion=crit, max_features=mf , random_state=seed)\n",
    "                    else:\n",
    "                        raise ValueError(\"Invalid model_type. Choose either 'RandomForest' or 'SklearnRandomForest'.\")\n",
    "                    \n",
    "                    # List to store accuracies for each fold\n",
    "                    fold_accuracies = []\n",
    "                    \n",
    "                    # Perform k-fold cross-validation\n",
    "                    for train_index, val_index in kf.split(X_train_val):\n",
    "                        # Split the data into training and validation sets for each fold\n",
    "                        X_training, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "                        y_training, y_val = y_train_val[train_index], y_train_val[val_index]\n",
    "                        \n",
    "                        # Train the model on the training set\n",
    "                        rf.fit(X_training, y_training)\n",
    "                        \n",
    "                        # Predict on the validation set\n",
    "                        y_pred = rf.predict(X_val)\n",
    "                        \n",
    "                        # Calculate accuracy for the current fold\n",
    "                        accuracy = accuracy_score(y_val, y_pred)\n",
    "                        fold_accuracies.append(accuracy)\n",
    "                    \n",
    "                    # Calculate average accuracy across all folds\n",
    "                    average_accuracy = np.mean(fold_accuracies)\n",
    "                    \n",
    "                    # Update best accuracy and hyperparameters if current average is better\n",
    "                    if average_accuracy > best_accuracy[0]:\n",
    "                        best_accuracy = [average_accuracy, maxdp, crit, mf]\n",
    "    \n",
    "    # Return the best hyperparameters and accuracy\n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning and testing my decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.8114285714285714), 5, 'gini', None]\n",
      "The best average accuracy is 0.8114285714285714 with Max_depth: 5, Criterion: gini, Max_features: None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find best values for hyperparameters for my own decision tree classifier\n",
    "best_hyperparameters_for_decisionTree = tune_decision_tree(\"DecisionTree\", X_train_val, y_train_val, decision_tree_max_depth_params, criterion, max_features, kf)\n",
    "\n",
    "print(best_hyperparameters_for_decisionTree)\n",
    "\n",
    "print(f\"The best average accuracy is {best_hyperparameters_for_decisionTree[0]} with Max_depth: {best_hyperparameters_for_decisionTree[1]}, Criterion: {best_hyperparameters_for_decisionTree[2]}, Max_features: {best_hyperparameters_for_decisionTree[3]}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation accuracy: 0.8314285714285714\n",
      "Test accuracy: 0.7933333333333333\n"
     ]
    }
   ],
   "source": [
    "# Testing my DecisionTree with the the hyperparameters\n",
    "\n",
    "rf = DecisionTree(max_depth=best_hyperparameters_for_decisionTree[1], criterion=best_hyperparameters_for_decisionTree[2], max_features=best_hyperparameters_for_decisionTree[3], seed=seed)\n",
    "\n",
    "rf.fit(X_train_val, y_train_val)\n",
    "\n",
    "print(f\"Training and validation accuracy: {accuracy_score(y_train_val, rf.predict(X_train_val))}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, rf.predict(X_test))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning and testing sklearn decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.8542857142857143), 5, 'gini', None]\n",
      "The best average accuracy is 0.8542857142857143 with Max_depth: 5, Criterion: gini, Max_features: None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find best values for hyperparameters for sklearn decision tree classifier\n",
    "best_hyperparameters_for_decisionTree_sklearn = tune_decision_tree(\"SklearnDecisionTree\", X_train_val, y_train_val, decision_tree_max_depth_params, criterion, max_features, kf)\n",
    "\n",
    "print(best_hyperparameters_for_decisionTree_sklearn)\n",
    "\n",
    "print(f\"The best average accuracy is {best_hyperparameters_for_decisionTree_sklearn[0]} with Max_depth: {best_hyperparameters_for_decisionTree_sklearn[1]}, Criterion: {best_hyperparameters_for_decisionTree_sklearn[2]}, Max_features: {best_hyperparameters_for_decisionTree_sklearn[3]}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation accuracy: 0.9171428571428571\n",
      "Test accuracy: 0.8133333333333334\n"
     ]
    }
   ],
   "source": [
    "# Testing sklearn decision tree with the the hyperparameters\n",
    "\n",
    "rf = DecisionTreeClassifier(max_depth=best_hyperparameters_for_decisionTree_sklearn[1], criterion=best_hyperparameters_for_decisionTree_sklearn[2], max_features=best_hyperparameters_for_decisionTree_sklearn[3], random_state=seed)\n",
    "\n",
    "rf.fit(X_train_val, y_train_val)\n",
    "\n",
    "print(f\"Training and validation accuracy: {accuracy_score(y_train_val, rf.predict(X_train_val))}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, rf.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning and testing my random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.8914285714285715), 2, 10, 'entropy', None]\n",
      "The best average accuracy is 0.8914285714285715 with N_estimators: 2, Max_depth: 10, Criterion: entropy, Max_features: None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find best values for hyperparameters for my own random forest classifier\n",
    "\n",
    "best_hypermeters_random_forest = tune_random_forest(\"RandomForest\",X_train_val, y_train_val, n_estimators, max_depth_params, criterion, max_features, kf)\n",
    "\n",
    "\n",
    "print(best_hypermeters_random_forest)\n",
    "\n",
    "print(f\"The best average accuracy is {best_hypermeters_random_forest[0]} with N_estimators: {best_hypermeters_random_forest[1]}, Max_depth: {best_hypermeters_random_forest[2]}, Criterion: {best_hypermeters_random_forest[3]}, Max_features: {best_hypermeters_random_forest[4]}.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation accuracy: 0.9228571428571428\n",
      "Test accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Testing the hyperparameters on test set with my own random forest classifier\n",
    "\n",
    "rf = RandomForest(n_estimators=best_hypermeters_random_forest[1], max_depth=best_hypermeters_random_forest[2], criterion=best_hypermeters_random_forest[3], max_features=best_hypermeters_random_forest[4], seed=seed)\n",
    "\n",
    "rf.fit(X_train_val,y_train_val)\n",
    "\n",
    "print(f\"Training and validation accuracy: {accuracy_score(y_train_val, rf.predict(X_train_val))}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, rf.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning and testing sklearn random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.8657142857142857), 10, 10, 'gini', 'sqrt']\n",
      "The best average accuracy is 0.8657142857142857 with N_estimators: 10, Max_depth: 10, Criterion: gini, Max_features: sqrt.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find best values for hyperparameters for sklearn random forest classifier\n",
    "\n",
    "best_hypermeters_random_forest_sklearn = tune_random_forest(\"SklearnRandomForest\",X_train_val, y_train_val, n_estimators, max_depth_params, criterion, max_features, kf)\n",
    "\n",
    "print(best_hypermeters_random_forest_sklearn)\n",
    "\n",
    "print(f\"The best average accuracy is {best_hypermeters_random_forest_sklearn[0]} with N_estimators: {best_hypermeters_random_forest_sklearn [1]}, Max_depth: {best_hypermeters_random_forest_sklearn [2]}, Criterion: {best_hypermeters_random_forest_sklearn [3]}, Max_features: {best_hypermeters_random_forest_sklearn [4]}.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation accuracy: 0.9857142857142858\n",
      "Test accuracy: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Testing the hyperparameters on test set\n",
    "rf = RandomForestClassifier(n_estimators=best_hypermeters_random_forest_sklearn[1], max_depth=best_hypermeters_random_forest_sklearn[2], criterion=best_hypermeters_random_forest_sklearn[3], max_features=best_hypermeters_random_forest_sklearn[4], random_state=seed)\n",
    "\n",
    "rf.fit(X_train_val,y_train_val)\n",
    "\n",
    "print(f\"Training and validation accuracy: {accuracy_score(y_train_val, rf.predict(X_train_val))}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, rf.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing my decision tree vs sklearn decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation accuracy: 0.8314285714285714\n",
      "Test accuracy: 0.7933333333333333\n"
     ]
    }
   ],
   "source": [
    "# My own decision tree:\n",
    "\n",
    "rf = DecisionTree(max_depth=best_hyperparameters_for_decisionTree[1], criterion=best_hyperparameters_for_decisionTree[2], max_features=best_hyperparameters_for_decisionTree[3], seed=seed)\n",
    "\n",
    "rf.fit(X_train_val, y_train_val)\n",
    "\n",
    "print(f\"Training and validation accuracy: {accuracy_score(y_train_val, rf.predict(X_train_val))}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, rf.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation accuracy: 0.9171428571428571\n",
      "Test accuracy: 0.8133333333333334\n"
     ]
    }
   ],
   "source": [
    "# Sklearn decision tree:\n",
    "\n",
    "rf = DecisionTreeClassifier(max_depth=best_hyperparameters_for_decisionTree_sklearn[1], criterion=best_hyperparameters_for_decisionTree_sklearn[2], max_features=best_hyperparameters_for_decisionTree_sklearn[3], random_state=seed)\n",
    "\n",
    "rf.fit(X_train_val, y_train_val)\n",
    "\n",
    "print(f\"Training and validation accuracy: {accuracy_score(y_train_val, rf.predict(X_train_val))}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, rf.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison:\n",
    "\n",
    "With seed=0 I get the following:\n",
    "\n",
    "My own decision tree:\n",
    "Test accuracy: 0.7933333333333333\n",
    "\n",
    "\n",
    "Sklearn decision tree:\n",
    "Test accuracy: 0.8133333333333334\n",
    "\n",
    "\n",
    "The sklearn classifier performs a little better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing my random forest vs sklearn random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation accuracy: 0.9228571428571428\n",
      "Test accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# My own random forest:\n",
    "rf = RandomForest(n_estimators=best_hypermeters_random_forest[1], max_depth=best_hypermeters_random_forest[2], criterion=best_hypermeters_random_forest[3], max_features=best_hypermeters_random_forest[4], seed=seed)\n",
    "\n",
    "rf.fit(X_train_val,y_train_val)\n",
    "\n",
    "print(f\"Training and validation accuracy: {accuracy_score(y_train_val, rf.predict(X_train_val))}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, rf.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation accuracy: 0.9857142857142858\n",
      "Test accuracy: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Sklearn random forest:\n",
    "rf = RandomForestClassifier(n_estimators=best_hypermeters_random_forest_sklearn[1], max_depth=best_hypermeters_random_forest_sklearn[2], criterion=best_hypermeters_random_forest_sklearn[3], max_features=best_hypermeters_random_forest_sklearn[4], random_state=seed)\n",
    "\n",
    "rf.fit(X_train_val,y_train_val)\n",
    "\n",
    "print(f\"Training and validation accuracy: {accuracy_score(y_train_val, rf.predict(X_train_val))}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, rf.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison:\n",
    "\n",
    "With seed=0 I get the following:\n",
    "\n",
    "My own random forest:\n",
    "Test accuracy: 0.8\n",
    "\n",
    "\n",
    "Sklearn random forest:\n",
    "Test accuracy: 0.8666666666666667\n",
    "\n",
    "\n",
    "The sklearn classifier performs a little better here also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Another Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns names: ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body', 'Balance', 'Uniformity', 'Sweetness']\n",
      "Target column name: CountryofOrigin\n",
      "X shape: (419, 8)\n",
      "y shape: (419,)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"coffee_data.csv\", delimiter=\",\", dtype=float, names=True)\n",
    "\n",
    "feature_names = list(data.dtype.names[:-1])\n",
    "target_name = data.dtype.names[-1]\n",
    "\n",
    "X = np.array([data[feature] for feature in feature_names]).T\n",
    "y = data[target_name].astype(int)\n",
    "\n",
    "print(f\"Feature columns names: {feature_names}\")\n",
    "print(f\"Target column name: {target_name}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into test and (validation and training)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X,y, test_size=0.3, random_state=seed, shuffle=True)\n",
    "\n",
    "# Use k fold cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning and testing my decision tree on coffee data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.7645236703682058), 5, 'entropy', None]\n",
      "The best average accuracy is 0.7645236703682058 with Max_depth: 5, Criterion: entropy, Max_features: None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find best values for hyperparameters for my own decision tree classifier\n",
    "best_hyperparameters_for_decisionTree = tune_decision_tree(\"DecisionTree\", X_train_val, y_train_val, decision_tree_max_depth_params, criterion, max_features, kf)\n",
    "\n",
    "print(best_hyperparameters_for_decisionTree)\n",
    "\n",
    "print(f\"The best average accuracy is {best_hyperparameters_for_decisionTree[0]} with Max_depth: {best_hyperparameters_for_decisionTree[1]}, Criterion: {best_hyperparameters_for_decisionTree[2]}, Max_features: {best_hyperparameters_for_decisionTree[3]}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation accuracy: 0.8156996587030717\n",
      "Test accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# Testing my DecisionTree with the the hyperparameters\n",
    "\n",
    "rf = DecisionTree(max_depth=best_hyperparameters_for_decisionTree[1], criterion=best_hyperparameters_for_decisionTree[2], max_features=best_hyperparameters_for_decisionTree[3], seed=seed)\n",
    "\n",
    "rf.fit(X_train_val, y_train_val)\n",
    "\n",
    "print(f\"Training and validation accuracy: {accuracy_score(y_train_val, rf.predict(X_train_val))}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, rf.predict(X_test))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning and testing my random forest on coffee data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.8572764465225013), 2, 15, 'entropy', None]\n",
      "The best average accuracy is 0.8572764465225013 with N_estimators: 2, Max_depth: 15, Criterion: entropy, Max_features: None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find best values for hyperparameters for my own random forest classifier\n",
    "\n",
    "best_hypermeters_random_forest = tune_random_forest(\"RandomForest\",X_train_val, y_train_val, n_estimators, max_depth_params, criterion, max_features, kf)\n",
    "\n",
    "\n",
    "print(best_hypermeters_random_forest)\n",
    "\n",
    "print(f\"The best average accuracy is {best_hypermeters_random_forest[0]} with N_estimators: {best_hypermeters_random_forest[1]}, Max_depth: {best_hypermeters_random_forest[2]}, Criterion: {best_hypermeters_random_forest[3]}, Max_features: {best_hypermeters_random_forest[4]}.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation accuracy: 0.9078498293515358\n",
      "Test accuracy: 0.7380952380952381\n"
     ]
    }
   ],
   "source": [
    "# Testing the hyperparameters on test set with my own random forest classifier\n",
    "\n",
    "rf = RandomForest(n_estimators=best_hypermeters_random_forest[1], max_depth=best_hypermeters_random_forest[2], criterion=best_hypermeters_random_forest[3], max_features=best_hypermeters_random_forest[4], seed=seed)\n",
    "\n",
    "rf.fit(X_train_val,y_train_val)\n",
    "\n",
    "print(f\"Training and validation accuracy: {accuracy_score(y_train_val, rf.predict(X_train_val))}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, rf.predict(X_test))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF264",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
