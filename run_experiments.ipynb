{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 â€“ Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Reload all modules without having to restart the kernel\n",
    "# Useful for development if you have edited any of the external code files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# My implementations\n",
    "from decision_tree import DecisionTree\n",
    "from random_forest import RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Do data loading, exploration and preprocessing as you see fit.\n",
    "\n",
    "Here is some code to load the dataset to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns names: ['citric_acid', 'residual_sugar', 'pH', 'sulphates', 'alcohol']\n",
      "Target column name: type\n",
      "X shape: (500, 5)\n",
      "y shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"wine_dataset_small.csv\", delimiter=\",\", dtype=float, names=True)\n",
    "\n",
    "feature_names = list(data.dtype.names[:-1])\n",
    "target_name = data.dtype.names[-1]\n",
    "\n",
    "X = np.array([data[feature] for feature in feature_names]).T\n",
    "y = data[target_name].astype(int)\n",
    "\n",
    "print(f\"Feature columns names: {feature_names}\")\n",
    "print(f\"Target column name: {target_name}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Set Random Seeds. Create a requirements.txt. Document Hyperparameters. Use Version Control. '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which hyperparameters should you tune?\n",
    "\n",
    "\"\"\" I think the max_depth, n_estimators(how many trees), criterion, max_features \"\"\"\n",
    "\n",
    "# Which values should you test for each hyperparameter?\n",
    "\n",
    "\"\"\"max_depth: 1 to 15?,    n_estimators: 1 to 200,   criterion: entropy or gini,  max_features: sqrt or log2 or None\"\"\"\n",
    "\n",
    "# Which model selection method should you use (e.g., hold-out validation, k-fold cross-validation)?\n",
    "\n",
    "\"\"\"k-fold cross-validation: This is ideal because it splits the dataset into k subsets (e.g., k=5), trains the model on k-1 folds, and tests on the remaining fold. The process is repeated k times with different folds. This helps to reduce the risk of overfitting to a particular subset of data.\n",
    "\n",
    "Why: It ensures that your model isn't overly tuned to any specific training or testing split and provides a more generalized measure of performance.\"\"\"\n",
    "\n",
    "# Which performance measure should you use for model selection (e.g., accuracy, F1-score)?\n",
    "\n",
    "\"\"\"Accuracy is fine becuase i think that there wont be class imbalance in the classes, if it were we should use F1-score. Try both\"\"\"\n",
    "\n",
    "# How do you ensure that your model selection process is fair and unbiased?\n",
    "\n",
    "\"\"\"follow best practices in data splitting, hyperparameter tuning, and evaluation. Avoid Data Leakage. Avoid Overfitting. Ensure Class Balance \"\"\"\n",
    "\n",
    "# How can you ensure reproducibility of your results?\n",
    "\n",
    "\"\"\"Set Random Seeds. Create a requirements.txt. Document Hyperparameters. Use Version Control. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9142857142857143 for max_depth: 2\n",
      "Average accuracy: 0.9257142857142858 for max_depth: 4\n",
      "Average accuracy: 0.9342857142857144 for max_depth: 8\n",
      "Average accuracy: 0.9342857142857144 for max_depth: 10\n",
      "Average accuracy: 0.9457142857142857 for max_depth: 20\n",
      "Average accuracy: 0.9342857142857144 for max_depth: 50\n",
      "Average accuracy: 0.9428571428571428 for max_depth: 100\n",
      "Average accuracy: 0.9428571428571428 for max_depth: 500\n",
      "\n",
      "\n",
      "The best accuracy is 0.9457142857142857 with max_depth at 20.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set seed \n",
    "seed = 0\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "#Split the data\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X,y, test_size=0.3, random_state=seed, shuffle=True)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Find best values for hyperparameters\n",
    "\n",
    "\n",
    "\n",
    "max_depth_params = [3,4,5,6,7,8,9,10,11,12,13,14,15,None]\n",
    "\n",
    "n_estimators =[2,4,8,10,20,50,100,500]\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for el in n_estimators:\n",
    "\n",
    "    rf = RandomForest(n_estimators=el, max_depth=10, criterion=\"gini\", max_features=\"sqrt\")\n",
    "\n",
    "    fold_accuracies = []\n",
    "    for train_index, val_index in kf.split(X_train_val):\n",
    "        \n",
    "        X_training, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "        y_training, y_val = y_train_val[train_index], y_train_val[val_index]\n",
    "        \n",
    "        rf.fit(X_training, y_training)\n",
    "        \n",
    "        \n",
    "        y_pred = rf.predict(X_val)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        \n",
    "        # print(f\"Fold accuracy: {accuracy}\")\n",
    "\n",
    "    # Average accuracy across all folds\n",
    "    average_accuracy = np.mean(fold_accuracies)\n",
    "    if (el is None):\n",
    "        accuracies.append([average_accuracy, el])\n",
    "    else:\n",
    "        accuracies.append([average_accuracy, int(el)])\n",
    "    print(f\"Average accuracy: {average_accuracy} for max_depth: {el}\")\n",
    "\n",
    "\n",
    "\n",
    "accuracies = np.array(accuracies)\n",
    "best_acc = np.argmax(accuracies[:,0])\n",
    "best_max_depth = accuracies[best_acc]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"The best accuracy is {best_max_depth[0]} with max_depth at {best_max_depth[1]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to sklearn\n",
    "# RandomForestClassifier(n_estimators=10, max_depth=5, criterion=\"entropy\", max_features=\"sqrt\")\n",
    "\n",
    "# fold_accuracies = []\n",
    "# for train_index, val_index in kf.split(X_train):\n",
    "    \n",
    "#     X_training, X_val = X_train[train_index], X_train[val_index]\n",
    "#     y_training, y_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "#     rf.fit(X_training, y_training)\n",
    "    \n",
    "    \n",
    "#     y_pred = rf.predict(X_val)\n",
    "    \n",
    "#     accuracy = accuracy_score(y_val, y_pred)\n",
    "#     fold_accuracies.append(accuracy)\n",
    "    \n",
    "#     print(f\"Fold accuracy: {accuracy}\")\n",
    "\n",
    "# # Average accuracy across all folds\n",
    "# average_accuracy = np.mean(fold_accuracies)\n",
    "# print(f\"Average accuracy: {average_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF264",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
